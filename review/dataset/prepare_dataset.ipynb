{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "\n",
    "# Make dataset\n",
    "\n",
    "This notebook contains the code to analyse content of the PubMedCentral Author Manuscript Collection. \\\n",
    "See: https://www.ncbi.nlm.nih.gov/pmc/about/mscollection/\n",
    "\n",
    "Files should be downloaded from https://ftp.ncbi.nlm.nih.gov/pub/pmc/manuscript/xml/ into  `~/pmc_dataset` folder.\n",
    "\n",
    "Resulting tables will be created under `~/review/dataset` folder (see `config.py`).\n",
    "\n",
    "Please ensure that env variable `PYTHONPATH` includes project folder to be able to import `review.config` module.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "% matplotlib inline\n",
    "% config InlineBackend.figure_format='retina'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import logging\n",
    "import os\n",
    "import sys\n",
    "\n",
    "import pandas as pd\n",
    "from IPython.display import display\n",
    "\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s %(levelname)s: %(message)s')\n",
    "\n",
    "import review.config as cfg\n",
    "\n",
    "pmc_dataset_root = os.path.expanduser('~/pmc_dataset')\n",
    "dataset_root = os.path.expanduser(cfg.dataset_path)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Collecting articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "from lxml import etree\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "dict_articles = {}\n",
    "\n",
    "for filelist in tqdm(glob(os.path.join(pmc_dataset_root, '*filelist.txt'))):\n",
    "    with open(filelist, 'r') as f:\n",
    "        for line in f:\n",
    "            if 'LastUpdated' in line:\n",
    "                continue\n",
    "            filename, pmcid, pmid, mid, date, time = line.split()\n",
    "            dict_articles[pmid] = filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print(list(dict_articles.items())[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "\n",
    "\n",
    "def split_text(text):\n",
    "    sents = nltk.tokenize.sent_tokenize(text)\n",
    "    res_sents = []\n",
    "    i = 0\n",
    "    while i < len(sents):\n",
    "        check = False\n",
    "        if i + 1 < len(sents):\n",
    "            check = sents[i + 1].strip()[0].islower() or sents[i + 1].strip()[0].isdigit()\n",
    "        made = sents[i]\n",
    "        while i + 1 < len(sents) and (made.endswith('Fig.') or check):\n",
    "            made += \" \" + \" \".join(sents[i + 1].strip().split())\n",
    "            i += 1\n",
    "            if i + 1 < len(sents):\n",
    "                check = sents[i + 1].strip()[0].islower() or sents[i + 1].strip()[0].isdigit()\n",
    "        res_sents.append(\" \".join(made.strip().split()))\n",
    "        i += 1\n",
    "    return res_sents\n",
    "\n",
    "\n",
    "def get_sentences(node):\n",
    "    def helper(node, is_disc):\n",
    "        if node.tag == 'xref':\n",
    "            ntail = ''\n",
    "            if node.tail is not None:\n",
    "                ntail = node.tail\n",
    "            res = f' xref_{node.get(\"ref-type\")}_{node.get(\"rid\")} ' + ntail\n",
    "            if res is None:\n",
    "                return '', ''\n",
    "            if is_disc:\n",
    "                return '', res\n",
    "            return res, ''\n",
    "        if node.tag == 'title':\n",
    "            if node.tail is None:\n",
    "                return '', ''\n",
    "            if is_disc:\n",
    "                return '', node.tail\n",
    "            return node.tail, ''\n",
    "        if not is_disc and node.find('title') is not None:\n",
    "            title = \"\".join(node.find('title').itertext()).lower()\n",
    "            if 'discussion' in title:\n",
    "                is_disc = True\n",
    "        st_text = ''\n",
    "        if node.text is not None:\n",
    "            st_text = node.text\n",
    "        if is_disc:\n",
    "            n_disc = st_text\n",
    "            n_gen = \"\"\n",
    "        else:\n",
    "            n_gen = st_text\n",
    "            n_disc = \"\"\n",
    "        for ch in node.getchildren():\n",
    "            gen, disc = helper(ch, is_disc)\n",
    "            n_gen += gen\n",
    "            n_disc += disc\n",
    "        tail = \"\"\n",
    "        if node.tail is not None:\n",
    "            tail = node.tail\n",
    "        if is_disc:\n",
    "            n_disc += tail\n",
    "        else:\n",
    "            n_gen += tail\n",
    "        return n_gen, n_disc\n",
    "\n",
    "    gen_res, disc_res = helper(node.find('body'), False)\n",
    "    gen_res = split_text(gen_res)\n",
    "    disc_res = split_text(disc_res)\n",
    "\n",
    "    abstract = \"\"\n",
    "\n",
    "    try:\n",
    "        abstract = \"\".join(node.find('front').find('article-meta').find('abstract').itertext())\n",
    "        abstract = \" \".join(abstract.strip().split())\n",
    "    except Exception:\n",
    "        pass\n",
    "    return gen_res, disc_res, abstract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "tree = etree.parse(f\"{pmc_dataset_root}/PMC004xxxxxx/PMC4239434.xml\")\n",
    "sents = get_sentences(tree.getroot())\n",
    "print(sents)\n",
    "print(len(sents[0]), len(sents[1]), len(sents[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def get_all_refs(node):\n",
    "    def get_cit_id_type(node):\n",
    "        if node.find('element-citation') is None:\n",
    "            return None\n",
    "        if node.find('element-citation').find('pub-id') is None:\n",
    "            return None\n",
    "        return node.find('element-citation').find('pub-id').get('pub-id-type')\n",
    "\n",
    "    def get_citation_info(node):\n",
    "        if node is None:\n",
    "            return {}\n",
    "        res = {}\n",
    "        for ch in node.getchildren():\n",
    "            if ch.tag == 'ref':\n",
    "                id_type = get_cit_id_type(ch)\n",
    "                if id_type is not None and id_type == 'pmid':\n",
    "                    res[ch.get('id')] = {\n",
    "                        'publication-type': ch.find('element-citation').get('publication-type'),\n",
    "                        'pmid': ch.find('element-citation').find('pub-id').text\n",
    "                    }\n",
    "        return res\n",
    "\n",
    "    def get_figs_info(node):\n",
    "        if node is None:\n",
    "            return {}\n",
    "        res = {}\n",
    "        for ch in node.getchildren():\n",
    "            if ch.tag == 'fig' and ch.find('caption') is not None:\n",
    "                res[ch.get('id')] = \" \".join(''.join(ch.find('caption').itertext()).strip().split())\n",
    "        return res\n",
    "\n",
    "    def get_tables_info(node):\n",
    "        if node is None:\n",
    "            return {}\n",
    "        res = {}\n",
    "        for ch in node.getchildren():\n",
    "            if ch.tag == 'table-wrap' and ch.find('caption') is not None:\n",
    "                res[ch.get('id')] = \" \".join(''.join(ch.find('caption').itertext()).strip().split())\n",
    "        return res\n",
    "\n",
    "    citations = get_citation_info(node.find('back').find('ref-list'))\n",
    "    figs = get_figs_info(node.find('floats-group'))\n",
    "    tables = get_tables_info(node.find('floats-group'))\n",
    "    return citations, figs, tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "get_all_refs(tree.getroot())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "pattern = re.compile(\"(?<=xref_bibr_)[\\d\\w]+\")\n",
    "\n",
    "\n",
    "def count_reverse(sents_gen, sents_disc, pmid):\n",
    "    result = []\n",
    "    for i, sent in enumerate(sents_gen):\n",
    "        results = re.findall(pattern, sent)\n",
    "        result.extend(list(map(lambda x: (pmid, 'general', str(i), x), results)))\n",
    "    for i, sent in enumerate(sents_disc):\n",
    "        results = re.findall(pattern, sent)\n",
    "        result.extend(list(map(lambda x: (pmid, 'discussion', str(i), x), results)))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "gen_sents, disc_sents, abst = get_sentences(tree.getroot())\n",
    "count_reverse(gen_sents, disc_sents, '2000292')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def is_review(tree):\n",
    "    try:\n",
    "        return any('Review' in sg.find('subject').text for sg in\n",
    "                   tree.find('front').find('article-meta').find('article-categories').findall('subj-group'))\n",
    "    except:\n",
    "        return False\n",
    "\n",
    "\n",
    "# Test\n",
    "is_review(etree.parse(f\"{pmc_dataset_root}/PMC001xxxxxx/PMC1817751.xml\").getroot())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Create tables required for model learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "! mkdir -p {dataset_root}\n",
    "\n",
    "print('Headers')\n",
    "with open(f'{dataset_root}/review_files.csv', 'w') as f:\n",
    "    print('pmid', file=f)\n",
    "with open(f'{dataset_root}/citations.csv', 'w') as f:\n",
    "    print('\\t'.join(['pmid', 'ref_id', 'pub_type', 'ref_pmid']), file=f)\n",
    "with open(f'{dataset_root}/sentences.csv', 'w') as f:\n",
    "    print('\\t'.join(['pmid', 'sent_id', 'type', 'sentence']), file=f)\n",
    "with open(f'{dataset_root}/abstracts.csv', 'w') as f:\n",
    "    print('\\t'.join(['pmid', 'abstract']), file=f)\n",
    "with open(f'{dataset_root}/figures.csv', 'w') as f:\n",
    "    print('\\t'.join(['pmid', 'fig_id', 'caption']), file=f)\n",
    "with open(f'{dataset_root}/tables.csv', 'w') as f:\n",
    "    print('\\t'.join(['pmid', 'tab_id', 'caption']), file=f)\n",
    "with open(f'{dataset_root}/reverse_ref.csv', 'w') as f:\n",
    "    print('\\t'.join(['pmid', 'sent_type', 'sent_id', 'ref_id']), file=f)\n",
    "\n",
    "print('Processing articles')\n",
    "for id, filename in tqdm(list(dict_articles.items())):\n",
    "    try:\n",
    "        tree = etree.parse(pmc_dataset_root + \"/\" + filename).getroot()\n",
    "        gen_sents, disc_sents, abstract = get_sentences(tree)\n",
    "        cits, figs, tables = get_all_refs(tree)\n",
    "    except Exception as e:\n",
    "        print(\"\\rsomething went wrong\", id, filename, e)\n",
    "        continue\n",
    "    if is_review(tree):\n",
    "        with open(f'{dataset_root}/review_files.csv', 'a') as f:\n",
    "            print(id, file=f)\n",
    "    with open(f'{dataset_root}/citations.csv', 'a') as f:\n",
    "        for i, dic in cits.items():\n",
    "            print('\\t'.join([id, str(i), dic['publication-type'], dic['pmid']]), file=f)\n",
    "    with open(f'{dataset_root}/sentences.csv', 'a') as f:\n",
    "        for i, sent in enumerate(gen_sents):\n",
    "            print('\\t'.join([id, str(i), 'general', sent]), file=f)\n",
    "        for i, sent in enumerate(disc_sents):\n",
    "            print('\\t'.join([id, str(i), 'discussion', sent]), file=f)\n",
    "    if abstract != '':\n",
    "        with open(f'{dataset_root}/abstracts.csv', 'a') as f:\n",
    "            print('\\t'.join([id, abstract]), file=f)\n",
    "    with open(f'{dataset_root}/figures.csv', 'a') as f:\n",
    "        for i, text in figs.items():\n",
    "            print('\\t'.join([id, i, text]), file=f)\n",
    "    with open(f'{dataset_root}/tables.csv', 'a') as f:\n",
    "        for i, text in tables.items():\n",
    "            print('\\t'.join([id, i, text]), file=f)\n",
    "    with open(f'{dataset_root}/reverse_ref.csv', 'a') as f:\n",
    "        res = count_reverse(gen_sents, disc_sents, id)\n",
    "        for row in res:\n",
    "            print('\\t'.join(list(row)), file=f)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Check dataset loading"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def sizeof_fmt(num, suffix='B'):\n",
    "    \"\"\"Used memory analysis utility\"\"\"\n",
    "    for unit in ['', 'Ki', 'Mi', 'Gi', 'Ti', 'Pi', 'Ei', 'Zi']:\n",
    "        if abs(num) < 1024.0:\n",
    "            return \"%3.1f %s%s\" % (num, unit, suffix)\n",
    "        num /= 1024.0\n",
    "    return \"%.1f %s%s\" % (num, 'Yi', suffix)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "logging.info('Loading citations_df')\n",
    "citations_df = pd.read_csv(os.path.join(dataset_root, \"citations.csv\"), sep='\\t')\n",
    "logging.info(sizeof_fmt(sys.getsizeof(citations_df)))\n",
    "display(citations_df.head())\n",
    "del citations_df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "logging.info('Loading review_files_df')\n",
    "review_files_df = pd.read_csv(os.path.join(dataset_root, \"review_files.csv\"), sep='\\t')\n",
    "logging.info(sizeof_fmt(sys.getsizeof(review_files_df)))\n",
    "display(review_files_df.head())\n",
    "del review_files_df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "logging.info('Loading reverse_ref_df')\n",
    "reverse_ref_df = pd.read_csv(os.path.join(dataset_root, \"reverse_ref.csv\"), sep='\\t')\n",
    "logging.info(sizeof_fmt(sys.getsizeof(reverse_ref_df)))\n",
    "display(reverse_ref_df.head())\n",
    "del reverse_ref_df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "logging.info('Loading abstracts_df')\n",
    "abstracts_df = pd.read_csv(os.path.join(dataset_root, \"abstracts.csv\"), sep='\\t')\n",
    "logging.info(sizeof_fmt(sys.getsizeof(abstracts_df)))\n",
    "display(abstracts_df.head())\n",
    "del abstracts_df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "logging.info('Loading figures_df')\n",
    "figures_df = pd.read_csv(os.path.join(dataset_root, \"figures.csv\"), sep='\\t')\n",
    "logging.info(sizeof_fmt(sys.getsizeof(figures_df)))\n",
    "display(figures_df.head())\n",
    "del figures_df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "logging.info('Loading tables_df')\n",
    "tables_df = pd.read_csv(os.path.join(dataset_root, \"tables.csv\"), sep='\\t')\n",
    "logging.info(sizeof_fmt(sys.getsizeof(tables_df)))\n",
    "display(tables_df.head())\n",
    "del tables_df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "logging.info('Loading sentences_df')\n",
    "sentences_df = pd.read_csv(os.path.join(dataset_root, \"sentences.csv\"), sep='\\t')\n",
    "logging.info(sizeof_fmt(sys.getsizeof(sentences_df)))\n",
    "display(sentences_df.head())\n",
    "del sentences_df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}